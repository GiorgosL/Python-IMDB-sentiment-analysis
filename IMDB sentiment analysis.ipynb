{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEaCAYAAADzDTuZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASiklEQVR4nO3df6xfdX3H8efLAv5CRpELMkopYv2BvwAbqCFZUDIobK440cGmdIakBmHThWyiMYMhbLJlGMmEWWNj2RRExdBtVdYQMuMPkArIDwujgkptB2Xl1+amAu/98f1c/O7ybe/tbe89l/t9PpKT7/f7Pp9z7vub3PTVc87nnJuqQpI03J7XdQOSpO4ZBpIkw0CSZBhIkjAMJEkYBpIkYLeuG5isfffdtxYsWNB1G5L0nPK9733v4aoaGVt/zobBggULWLduXddtSNJzSpIfD6p7mkiSZBhIkgwDSRKGgSQJw0CSxATCIMlBSW5Isj7JXUk+0OrnJ/lpktvaclLfNh9OsiHJPUlO6KsvabUNSc7tqx+S5KYk9yb5YpI9dvUXlSRt20SODJ4Ezqmq1wCLgbOSHNbWfaKqDm/LGoC27lTgtcAS4LIkc5LMAT4FnAgcBpzWt5+L274WAo8AZ+yi7ydJmoBxw6CqNlfVLe39E8B64MDtbLIUuKqqfl5V9wMbgKPasqGq7quqXwBXAUuTBHgr8OW2/Srg5Ml+IUnSjtuhm86SLACOAG4CjgHOTnI6sI7e0cMj9ILixr7NNvKr8HhgTP1o4KXAo1X15IDxY3/+cmA5wPz583ek9c4sOPdfum5h1vjRx3+r6xZmFX83d63n+u/nhC8gJ9kT+Arwwap6HLgcOBQ4HNgM/O3o0AGb1yTqzy5WraiqRVW1aGTkWXdTS5ImaUJHBkl2pxcEn6+qawCq6sG+9Z8B/rl93Agc1Lf5PGBTez+o/jCwd5Ld2tFB/3hJ0jSYyGyiAJ8F1lfVJX31A/qGvR24s71fDZya5PlJDgEWAt8FbgYWtplDe9C7yLy6en+E+QbglLb9MuDanftakqQdMZEjg2OA9wB3JLmt1T5CbzbQ4fRO6fwIeB9AVd2V5GrgB/RmIp1VVU8BJDkbuA6YA6ysqrva/j4EXJXkQuBWeuEjSZom44ZBVX2Twef112xnm4uAiwbU1wzarqruozfbSJLUAe9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQmEAZJDkpyQ5L1Se5K8oFW3yfJ2iT3tte5rZ4klybZkOT2JEf27WtZG39vkmV99TcluaNtc2mSTMWXlSQNNpEjgyeBc6rqNcBi4KwkhwHnAtdX1ULg+vYZ4ERgYVuWA5dDLzyA84CjgaOA80YDpI1Z3rfdkp3/apKkiRo3DKpqc1Xd0t4/AawHDgSWAqvasFXAye39UuCK6rkR2DvJAcAJwNqq2lpVjwBrgSVt3V5V9Z2qKuCKvn1JkqbBDl0zSLIAOAK4Cdi/qjZDLzCA/dqwA4EH+jbb2Grbq28cUB/085cnWZdk3ZYtW3akdUnSdkw4DJLsCXwF+GBVPb69oQNqNYn6s4tVK6pqUVUtGhkZGa9lSdIETSgMkuxOLwg+X1XXtPKD7RQP7fWhVt8IHNS3+Txg0zj1eQPqkqRpMpHZRAE+C6yvqkv6Vq0GRmcELQOu7auf3mYVLQYea6eRrgOOTzK3XTg+HriurXsiyeL2s07v25ckaRrsNoExxwDvAe5IclurfQT4OHB1kjOAnwDvbOvWACcBG4CfAe8FqKqtST4G3NzGXVBVW9v7M4HPAS8EvtYWSdI0GTcMquqbDD6vD3DcgPEFnLWNfa0EVg6orwNeN14vkqSp4R3IkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksQEwiDJyiQPJbmzr3Z+kp8mua0tJ/Wt+3CSDUnuSXJCX31Jq21Icm5f/ZAkNyW5N8kXk+yxK7+gJGl8Ezky+BywZED9E1V1eFvWACQ5DDgVeG3b5rIkc5LMAT4FnAgcBpzWxgJc3Pa1EHgEOGNnvpAkaceNGwZV9Q1g6wT3txS4qqp+XlX3AxuAo9qyoaruq6pfAFcBS5MEeCvw5bb9KuDkHfwOkqSdtDPXDM5Ocns7jTS31Q4EHugbs7HVtlV/KfBoVT05pi5JmkaTDYPLgUOBw4HNwN+2egaMrUnUB0qyPMm6JOu2bNmyYx1LkrZpUmFQVQ9W1VNV9TTwGXqngaD3P/uD+obOAzZtp/4wsHeS3cbUt/VzV1TVoqpaNDIyMpnWJUkDTCoMkhzQ9/HtwOhMo9XAqUmen+QQYCHwXeBmYGGbObQHvYvMq6uqgBuAU9r2y4BrJ9OTJGnydhtvQJIrgWOBfZNsBM4Djk1yOL1TOj8C3gdQVXcluRr4AfAkcFZVPdX2czZwHTAHWFlVd7Uf8SHgqiQXArcCn91l306SNCHjhkFVnTagvM1/sKvqIuCiAfU1wJoB9fv41WkmSVIHvANZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJElMIAySrEzyUJI7+2r7JFmb5N72OrfVk+TSJBuS3J7kyL5tlrXx9yZZ1ld/U5I72jaXJsmu/pKSpO2byJHB54AlY2rnAtdX1ULg+vYZ4ERgYVuWA5dDLzyA84CjgaOA80YDpI1Z3rfd2J8lSZpi44ZBVX0D2DqmvBRY1d6vAk7uq19RPTcCeyc5ADgBWFtVW6vqEWAtsKSt26uqvlNVBVzRty9J0jSZ7DWD/atqM0B73a/VDwQe6Bu3sdW2V984oD5QkuVJ1iVZt2XLlkm2Lkkaa1dfQB50vr8mUR+oqlZU1aKqWjQyMjLJFiVJY002DB5sp3horw+1+kbgoL5x84BN49TnDahLkqbRZMNgNTA6I2gZcG1f/fQ2q2gx8Fg7jXQdcHySue3C8fHAdW3dE0kWt1lEp/ftS5I0TXYbb0CSK4FjgX2TbKQ3K+jjwNVJzgB+AryzDV8DnARsAH4GvBegqrYm+Rhwcxt3QVWNXpQ+k96MpRcCX2uLJGkajRsGVXXaNlYdN2BsAWdtYz8rgZUD6uuA143XhyRp6ngHsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCSxk2GQ5EdJ7khyW5J1rbZPkrVJ7m2vc1s9SS5NsiHJ7UmO7NvPsjb+3iTLdu4rSZJ21K44MnhLVR1eVYva53OB66tqIXB9+wxwIrCwLcuBy6EXHsB5wNHAUcB5owEiSZoeU3GaaCmwqr1fBZzcV7+iem4E9k5yAHACsLaqtlbVI8BaYMkU9CVJ2oadDYMC/jXJ95Isb7X9q2ozQHvdr9UPBB7o23Zjq22rLkmaJrvt5PbHVNWmJPsBa5PcvZ2xGVCr7dSfvYNe4CwHmD9//o72Kknahp06MqiqTe31IeCr9M75P9hO/9BeH2rDNwIH9W0+D9i0nfqgn7eiqhZV1aKRkZGdaV2S1GfSYZDkxUleMvoeOB64E1gNjM4IWgZc296vBk5vs4oWA4+100jXAccnmdsuHB/fapKkabIzp4n2B76aZHQ/X6iqrye5Gbg6yRnAT4B3tvFrgJOADcDPgPcCVNXWJB8Dbm7jLqiqrTvRlyRpB006DKrqPuCNA+r/CRw3oF7AWdvY10pg5WR7kSTtHO9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSMygMkixJck+SDUnO7bofSRomMyIMkswBPgWcCBwGnJbksG67kqThMSPCADgK2FBV91XVL4CrgKUd9yRJQ2O3rhtoDgQe6Pu8ETh67KAky4Hl7eN/JblnGnobBvsCD3fdxHhycdcdqCP+fu5aBw8qzpQwyIBaPatQtQJYMfXtDJck66pqUdd9SIP4+zk9Zsppoo3AQX2f5wGbOupFkobOTAmDm4GFSQ5JsgdwKrC6454kaWjMiNNEVfVkkrOB64A5wMqquqvjtoaJp940k/n7OQ1S9axT85KkITNTThNJkjpkGEiSDANJkmEw1JK8MMmruu5DUvcMgyGV5G3AbcDX2+fDkzidVzNCet6d5M/b5/lJjuq6r9nMMBhe59N7JtSjAFV1G7Cgw36kfpcBbwZOa5+foPcwS02RGXGfgTrxZFU9lgx6EojUuaOr6sgktwJU1SPthlRNEcNgeN2Z5PeBOUkWAn8MfLvjnqRRv2yPti+AJCPA0922NLt5mmh4/RHwWuDnwBeAx4APdtqR9CuXAl8F9ktyEfBN4C+7bWl28w7kIZXkiKq6tes+pG1J8mrgOHpPNb6+qtZ33NKsZhgMqSQ3AAcAXwKu8llQmkmSfBL4YlV56nKaeJpoSFXVW4BjgS3AiiR3JPlot11Jz7gF+Gj7m+h/k8S/ZzDFPDIQSV4P/Bnwe1XljA3NGEn2Ad5B77H286tqYcctzVoeGQypJK9Jcn6SO4G/ozeTaF7HbUljvQJ4Nb17YO7utpXZzSODIZXkRuBK4EtV5V+V04yS5GLgd4EfAlcD11TVo912Nbt5n8GQqqrFXfcgbcf9wJur6uGuGxkWHhkMmSRXV9W7ktxBu6FndBVQVfWGjlqTSPLqqro7yZGD1lfVLdPd07AwDIZMkgOqanOSgwetr6ofT3dP0qgkK6pqeZv6PFZV1VunvakhYRgMqSQXV9WHxqtJXUjygqr63/Fq2nWcTTS8fnNA7cRp70IabNDNZt6ANoW8gDxkkpwJvB94eZLb+1a9BPhWN11JPUleBhwIvDDJEfSuZQHsBbyos8aGgKeJhkySXwPmAn8FnNu36omq2tpNV1JPkmXAHwKLgHV9q54APldV13TR1zAwDIZckv2AF4x+rqqfdNiOBECSd1TVV7ruY5gYBkOq/dnLS4BfBx4CDgbWV9VrO21MQy3Ju6vqH5Ocw/+f+gxAVV3SQVtDwQvIw+tCYDHw71V1CL1HBXvNQF17cXvdk951rLGLpohHBkMqybqqWpTk+8ARVfV0ku9WlX90XBpCHhkMr0eT7Al8A/h8e378kx33JAGQ5K+T7JVk9yTXJ3k4ybu77ms2MwyG11Lgf4A/Ab5O74Fgb+u0I+lXjq+qx4HfBjYCrwT+tNuWZjfvMxhSVfXffR9XddaINNju7fUk4Mqq2ppke+O1kwyDIZXkCZ49W+MxenO7z6mq+6a/K+kZ/5TkbnpHr+9PMgL4KIop5AXkIZXkL4BNwBfo3eV5KvAy4B7gzKo6trvuJEgyF3i8qp5K8iJgr6r6j677mq0MgyGV5KaqOnpM7caqWpzk+1X1xq56k5LsDpwJ/EYr/Rvw91X1y+66mt28gDy8nk7yriTPa8u7+tb5PwR17XLgTcBlbTmy1TRFPDIYUkleDnwSeDO9f/xvpDez6KfAm6rqmx22pyE36OjUI9ap5QXkIdUuEG9rKqlBoK49leTQqvohPPOfl6c67mlWMwyGVJJX0jvs3r+qXpfkDcDvVNWFHbcmQe+eghuSjM5qWwC8t7t2Zj+vGQyvzwAfBn4JUFW305tRJM0E3wI+DTzdlk8D3+m0o1nOMBheL6qq746p+TgKzRRXAIcAH2vLIcA/dNrRLOdpouH1cJJDaTOHkpwCbO62JekZrxpzsfiG9lBFTRHDYHidBawAXp3kp8D9wB9025L0jFuTLK6qGwGSHI2PWJ9STi0dUkmeD5xC78LcPsDjQFXVBV32JQEkWQ+8Chj9y3vzgfX0rh9UVb2hq95mK48Mhte1wKPALfQeSyHNJEu6bmDYeGQwpJLcWVWv67oPSTODs4mG17eTvL7rJiTNDB4ZDKkkPwBeQe/C8c/pPbnUc7HSkDIMhlSSgwfVq+rH092LpO4ZBpIkrxlIkgwDSRKGgSQJw0CShGEgSQL+D0IGT4v6y4EMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.sentiment.value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    text = re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    \n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop]\n",
    "        \n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "def stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(normalise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.review\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the categorical statemnt\n",
    "lb = LabelBinarizer()\n",
    "train_sentiment = lb.fit_transform(y_train)\n",
    "test_sentiment = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_performance(y_test, y_pred, model):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * precision * recall / (precision + recall) \n",
    "    auc_roc = round(roc_auc_score(y_score = y_pred, y_true = y_test),2)\n",
    "    model_name = model\n",
    "    result = pd.DataFrame({\n",
    "                         'Model' : [model_name],\n",
    "                         'Accuracy':[accuracy],\n",
    "                         'Precision' : [precision],\n",
    "                         'Recall': [recall],\n",
    "                         'f1 score' : [f1_score],\n",
    "                        })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW - tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bag of words__ is a word representation technique that counts the occurence of words existing within documents in the corpus.\n",
    "\n",
    "\n",
    "Term frequency inverted document frequency __(tfidf)__ attempts to weight the importance of a word reversely to its frequency within a document. This is attributed to the fact that highly occuring words within a document might not bear as much of contextual information as less occuring words, which could be more descriptive about the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_train_reviews = cv.fit_transform(X_train)\n",
    "cv_test_reviews = cv.transform(X_test)\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tv_train_reviews = tv.fit_transform(X_train)\n",
    "tv_test_reviews = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistric Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = seed)\n",
    "\n",
    "lr_bow = lr.fit(cv_train_reviews, train_sentiment)\n",
    "lr_tfidf = lr.fit(tv_train_reviews, train_sentiment)\n",
    "\n",
    "lr_bow_predict = lr.predict(cv_test_reviews)\n",
    "lr_tfidf_predict = lr.predict(tv_test_reviews)\n",
    "\n",
    "lr_bow_score = binary_classification_performance(test_sentiment, lr_bow_predict, 'Logistic Regression BoW')\n",
    "lr_tfidf_score = binary_classification_performance(test_sentiment, lr_tfidf_predict, 'Logistic Regression tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb_bow = mnb.fit(cv_train_reviews,train_sentiment)\n",
    "mnb_tfidf = mnb.fit(tv_train_reviews,train_sentiment)\n",
    "\n",
    "mnb_bow_predict = mnb.predict(cv_test_reviews)\n",
    "mnb_tfidf_predict = mnb.predict(tv_test_reviews)\n",
    "\n",
    "mnb_bow_score = binary_classification_performance(test_sentiment,mnb_bow_predict, 'Naive Bayes BoW')\n",
    "mnb_tfidf_score = binary_classification_performance(test_sentiment,mnb_tfidf_predict, 'Naive Bayes tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ngrams__ are sets of continuous words found within a document. Their length can be extended by the configurable number parameter. In this case a (1,2) ngram is being selected, meaning a set of two words. Ngrams facilitate text classification as words which bear contextual meaning are matched together.\n",
    "\n",
    "e.g; The neighbour's dog barks loudly -> {The neighbour's} - {neighbour's dog} - {dog barks} - {barks loudly}.\n",
    "\n",
    "As seen on the example above the created ngram can be more representive about a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))\n",
    "cv_train_reviews = cv.fit_transform(X_train)\n",
    "cv_test_reviews = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(ngram_range = (1,2))\n",
    "tv_train_reviews = tv.fit_transform(X_train)\n",
    "tv_test_reviews = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = seed)\n",
    "\n",
    "lr_bow = lr.fit(cv_train_reviews, train_sentiment)\n",
    "lr_tfidf = lr.fit(tv_train_reviews, train_sentiment)\n",
    "\n",
    "lr_bow_predict = lr.predict(cv_test_reviews)\n",
    "lr_tfidf_predict = lr.predict(tv_test_reviews)\n",
    "\n",
    "lr_bow_score_ngram = binary_classification_performance(test_sentiment, lr_bow_predict, 'Logistic Regression BoW ngram')\n",
    "lr_tfidf_score_ngram = binary_classification_performance(test_sentiment, lr_tfidf_predict, 'Logistic Regression tfidf ngram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb_bow = mnb.fit(cv_train_reviews,train_sentiment)\n",
    "mnb_tfidf = mnb.fit(tv_train_reviews,train_sentiment)\n",
    "\n",
    "mnb_bow_predict = mnb.predict(cv_test_reviews)\n",
    "mnb_tfidf_predict = mnb.predict(tv_test_reviews)\n",
    "\n",
    "mnb_bow_score_ngram = binary_classification_performance(test_sentiment,mnb_bow_predict, 'Naive Bayes BoW ngram')\n",
    "mnb_tfidf_score_ngram = binary_classification_performance(test_sentiment,mnb_tfidf_predict, 'Naive Bayes tfidf ngram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = (lr_bow_score, lr_tfidf_score, mnb_bow_score, mnb_tfidf_score, \n",
    "       lr_bow_score_ngram, lr_tfidf_score_ngram, mnb_bow_score_ngram, mnb_tfidf_score_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression tfidf</th>\n",
       "      <td>0.889030</td>\n",
       "      <td>0.879033</td>\n",
       "      <td>0.903521</td>\n",
       "      <td>0.891109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression tfidf ngram</th>\n",
       "      <td>0.886788</td>\n",
       "      <td>0.875058</td>\n",
       "      <td>0.903763</td>\n",
       "      <td>0.889179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes tfidf ngram</th>\n",
       "      <td>0.884182</td>\n",
       "      <td>0.895108</td>\n",
       "      <td>0.871684</td>\n",
       "      <td>0.883241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes BoW ngram</th>\n",
       "      <td>0.875515</td>\n",
       "      <td>0.902140</td>\n",
       "      <td>0.843825</td>\n",
       "      <td>0.872009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression BoW</th>\n",
       "      <td>0.867818</td>\n",
       "      <td>0.840749</td>\n",
       "      <td>0.909190</td>\n",
       "      <td>0.873631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression BoW ngram</th>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.849450</td>\n",
       "      <td>0.884588</td>\n",
       "      <td>0.866663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes tfidf</th>\n",
       "      <td>0.857333</td>\n",
       "      <td>0.867450</td>\n",
       "      <td>0.845273</td>\n",
       "      <td>0.856218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes BoW</th>\n",
       "      <td>0.855333</td>\n",
       "      <td>0.893929</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.848800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy  Precision    Recall  f1 score\n",
       "Model                                                                   \n",
       "Logistic Regression tfidf        0.889030   0.879033  0.903521  0.891109\n",
       "Logistic Regression tfidf ngram  0.886788   0.875058  0.903763  0.889179\n",
       "Naive Bayes tfidf ngram          0.884182   0.895108  0.871684  0.883241\n",
       "Naive Bayes BoW ngram            0.875515   0.902140  0.843825  0.872009\n",
       "Logistic Regression BoW          0.867818   0.840749  0.909190  0.873631\n",
       "Logistic Regression BoW ngram    0.863212   0.849450  0.884588  0.866663\n",
       "Naive Bayes tfidf                0.857333   0.867450  0.845273  0.856218\n",
       "Naive Bayes BoW                  0.855333   0.893929  0.808008  0.848800"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.set_index('Model').sort_values('Accuracy', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
